# :dizzy: alakazam :spoon: : A command line interface for Pokemon VGC calculations

alakazam is a chatbot-like interface for running calculations for the Pokemon video games Pokemon Scarlet and Pokemon Violet, specifically for standard doubles (VGC) competitive play. Think of it like a standard damage calculator, except with natural language instructions instead!

Simply type in a calculation you wish to compute, and the app will parse your natural language instructions and return the result, just like magic!

Alakazam only works for speed checks right now, but advanced capabilites such as damage calcs are incoming! If there's something specific you'd want to see, please open an issue. Thanks, and enjoy!


## Table of Contents
- [Usage](#usage)
- [How It Works](#how-it-works)
- [Stack](#stack)
- [Features](#features)
- [Roadmap](#roadmap)
- [License](#license)
- [Contact Information](#contact-information)

## Usage

Navigate to the deployed [Streamlit web application here](https://alakazam.streamlit.app/).

From here, just type in a natural language command and hit enter! It may take up to fifteen seconds to get your first response. After submitting a few responses, latency should decrease to about four seconds.

Submitted results are cached in the app so you can keep track of your calcs.

## How it Works
When VGC players communicate the game state of a Pokemon match, they use a certain lingo usually called a damage calc. I wanted to know if I could train a large language model to parse these damage calcs and speed checks, to compute them directly instead of tediously using a interface like Pokemon Damage Calculator.


Alakazam uses an augmented finetuned large langauge model to compute speed checks. A pretrained large langauge model was instruction finetuned using LoRA techniques on a synthetic dataset containing pokemon names in a formatted calc phrasing. After parsing the damage calc, the model passes this information to a set of scripts to do the actual math. The results are returned directly back to the user, much like a computer command line interface.

## Stack

We use [Streamlit](https://streamlit.io) for the web application, and Streamlit Cloud to host it.

We use [Modal](https://modal.com) to host a finetuned large language model model for parsing user commands.

We use [langchain](https://api.python.langchain.com/en/latest/) to generate examples, and we use [PokeAPI](https://pokeapi.co) to get the data about the games and Pokemon for the app to lookup.

We use [Supabase](https://supabase.com) to store queries made by users, so we can learn about what users request and what calcs work.

We use [Hugging Face](https://huggingface.co) (transformers, peft) and [Google Colab](https://colab.research.google.com) to finetune an instance of a 560million parameter [BLOOM](https://huggingface.co/bigscience/bloom-560m#uses) model from BigScience.


## Features

- Fast calculation of natural language speed checks
- History to keep track of previous calculations

## Roadmap
- Add chatbot functionality (Retrieval Augmented Generation) to external useful data sources (like an items dictionary, or berry dict, or game knowledge)
- Submit multiple calcs at once for comparison
- Calculate more advanced queries such as "When does X outspeed y?"
- Add full damage calc capability

## Safety

When using large language models such as BLOOM, we must be careful to warn users about potentially inappropriate and errand output that these models can generate.

The current implementation of alakazam does not allow for free-form generation to be surfaced directly to users. Additionally, we check for output that we'd expect for our speed check calculations, and fail safely if we don't get a generation along those lines. In other words, it should not be possible to easily generate harmful content with this app.

If you see inappropriate or offensive output generated by this model, please contact the repo maintainer Arjun Patel with a screenshot and prompt used to obtain this behavior. Thanks!

## Acknowledgements

Shoutout to Chris Alexiuk for his finetuning script with LoRa/PEFT, which is what I modified to train my model.

Thanks to Full Stack Deep Learning's free online LLM Bootcamp, where I learned how to use Modal and how to think about structuring my web application.

## License

The underlying bloom model uses the BigScience Bloom RAIL 1.0 License. Please be aware that any derivatives of this application will have to incorporate this license.

